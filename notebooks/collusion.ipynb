{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collusive Voting\n",
    "\n",
    "## Introduction\n",
    "\n",
    "It is a well-documented phenomenon that Eurovision members generally have voting biases towards (and against) other specific members, suggesting that countries may not be voting entirely on the quality and popularity of entry songs alone. \n",
    "\n",
    "To this end, we implement a modified version of the collusion detection algorithm introduced in [Derek Gatherer's paper in the Journal of Artificial Societies and Social Simulation](http://jasss.soc.surrey.ac.uk/9/2/1.html). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading and cleaning data\n",
    "\n",
    "The data is obtained from [datagraver](https://data.world/datagraver/eurovision-song-contest-scores-1975-2019/workspace/file?filename=eurovision_song_contest_1975_2019v5.xlsx), with some incorrect information edited out, such as Belarus giving Russia both 12 (correct) and 0 (incorrect) televote points in the 2019 grand final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "# initialize random seed\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "\n",
    "\n",
    "# import common functions\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/modules\")\n",
    "\n",
    "import functions as common_functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original:https://data.world/datagraver/eurovision-song-contest-scores-1975-2019/workspace/file?filename=eurovision_song_contest_1975_2019v5.xlsx\n",
    "# note that the data for 2019 Final: Belarus has been corrected by removing incorrect score reports. In addition, 2018f's \"The Netherands\" has been corrected to \"The Netherlands\".\n",
    "csv = pd.read_csv(\"./eurovision_song_contest_1975_2019v5.csv\")\n",
    "\n",
    "csv.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean / modify CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "csv = csv.rename(columns={\"Jury or Televoting\" : \"Jury_or_Televoting\", \"From country\": \"From_country\", \"To country\" : \"To_country\"})\n",
    "\n",
    "# select only grand finals data\n",
    "csv = csv[ (csv[\"(semi-) final\"] == \"f\") & (csv[\"Duplicate\"] != \"x\") & (csv[\"From_country\"] != csv[\"To_country\"]) ] \n",
    "\n",
    "# select only relevant columns and drop duplicates\n",
    "csv = csv[ [\"Year\", \"Jury_or_Televoting\", \"From_country\", \"To_country\", \"Points\"] ].drop_duplicates()\n",
    "\n",
    "# rename FYR Macedonia to North Macedonia. This choice is arbitrary and not meant to be political.\n",
    "csv[\"From_country\"].replace({\"F.Y.R. Macedonia\": \"North Macedonia\"}, inplace=True)\n",
    "csv[\"To_country\"].replace({\"F.Y.R. Macedonia\": \"North Macedonia\"}, inplace=True)\n",
    "\n",
    "csv.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for collusive voting, combine the jury and televoting votes.\n",
    "combined_csv = csv.join(\n",
    "    csv.set_index([\"Year\", \"From_country\", \"To_country\"]), \n",
    "    on=[\"Year\", \"From_country\", \"To_country\"], \n",
    "    lsuffix=\"_Jury\", \n",
    "    rsuffix=\"_Televote\",\n",
    "    how=\"right\"\n",
    ")\n",
    "combined_csv = combined_csv[(combined_csv.Year < 2016) | ( (combined_csv.Year >= 2016) & (combined_csv.Jury_or_Televoting_Jury == \"J\") & (combined_csv.Jury_or_Televoting_Televote == \"T\") )]\n",
    "\n",
    "combined_csv.loc[combined_csv.Year <= 2015, \"Points_Televote\"] = 0 # Dual voting begun in 2016\n",
    "\n",
    "combined_csv.drop(['Jury_or_Televoting_Jury', 'Jury_or_Televoting_Televote'], axis=1, inplace=True)\n",
    "\n",
    "combined_csv[\"Points_total\"] = combined_csv[\"Points_Jury\"] + combined_csv[\"Points_Televote\"]\n",
    "\n",
    "# sample\n",
    "combined_csv[  (combined_csv.From_country == \"Belgium\") & (combined_csv.Year == 2019)].sort_values([\"Points_Televote\", \"Points_Jury\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_each_year(csv):\n",
    "    grouped = csv[ [\"Year\", \"From_country\", \"Points_Jury\", \"Points_Televote\"] ].groupby([\"Year\", \"From_country\"]).max()\n",
    "    by_year = grouped.groupby([\"Year\"]) \n",
    "    max_possible_points = by_year.Points_Jury.max() + by_year.Points_Televote.max()\n",
    "    televote_by_year = (by_year.Points_Televote.max() != 0)\n",
    "    return max_possible_points, televote_by_year\n",
    "\n",
    "# calculate the maximum amount of points a country can receive each year, and put it into a column. Note that this not simply \"number of countries voting * 12\". \n",
    "MAX_POSSIBLE_POINTS_RECEIVED, HAS_TELEVOTE_BY_YEAR = max_each_year(combined_csv)\n",
    "points = combined_csv.join(MAX_POSSIBLE_POINTS_RECEIVED.to_frame(name=\"highest\"), on=[\"Year\"])\n",
    "points.Points_Jury /= points[\"highest\"]\n",
    "points.Points_Televote /= points[\"highest\"]\n",
    "points.Points_total /= points[\"highest\"]\n",
    "\n",
    "points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTICIPANTS_BY_YEAR = points.groupby([\"Year\", \"From_country\"])\n",
    "PARTICIPANTS_BY_YEAR = PARTICIPANTS_BY_YEAR.count()[\"To_country\"].groupby(level=\"Year\").count()\n",
    "PARTICIPANTS_BY_YEAR.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Favouritism and Collusion Detection Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "Question: Did country X give an abnormal amount of points (indicating favouritism) from years A to B?\n",
    "\n",
    "Define `FAVOURITISM(X, Y, A, B)` as follows:\n",
    "\n",
    "0. Determine which years that X actually voted for Y (since it is possible that X could not vote for Y in some years). Let this list of years be `TIMESPAN`.\n",
    "\n",
    "1. Obtain the number of points given from X to Y in the `TIMESPAN`, divided by the maximum number of points a country can receive each year. Take the average of those values (which are percentages) be $\\bar{x}$.\n",
    "\t* Using a percentage of the maximum number of points received allows us to take into accounts of years with separate televotes.\n",
    "\n",
    "2. Simulate many scenarios where country X gives country Y a random number of points, averaged over `TIMESPAN`. Collect these simulations into a list called $S$.\n",
    "\n",
    "3. Sort $S$ to obtain a simulated average vote which follows a normal distribution.\n",
    "\n",
    "4. If $\\bar{x}$ is greater than the 5th _highest_ percentile of $S$, then we can say with 95% confidence that country X has collusively voted for country Y.\n",
    "\t* In other words, country X has given country Y an exceptionally and abnormally high amount of points, indicating favouritism.\n",
    "\n",
    "5. If the same is true for `FAVOURITISM(Y, X, A, B)` then there is collusion between countries X and Y.\n",
    "\t* That is, `COLLUSION(X, Y, A, B) == (FAVOURITISM(X, Y, A, B) and FAVOURITISM(Y, X, A, B))`.\n",
    "\n",
    "The full algorithm is shown below:\n",
    "\n",
    "```\n",
    "INPUT: START_YEAR, END_YEAR, SIGNIFICANCE, TABULATION (of actual scores)\n",
    "For each pair of countries (DONOR to RECIPIENT) {\n",
    "\tFrom TABULATION, select actual results DONOR to RECIPIENT between START_YEAR and END_YEAR\n",
    "\tCalculate actual average vote from DONOR to RECIPIENT between START_YEAR and END_YEAR\n",
    "\tInitialise array AVERAGE_SIMULATION\n",
    "\tFor 100000 iterations {\n",
    "\t\t# simulate an average score that DONOR gives to RECIPIENT from START_YEAR to END_YEAR\n",
    "\t\tInitialise array ONE_SIMULATION \n",
    "\t\tFor each year from START_YEAR to END_YEAR { \n",
    "\t\t\tDetermine NUM, number of countries voting that year\n",
    "\t\t\tDerive simulated position by RAND * (NUM-1), rounded up to nearest integer\n",
    "\t\t\tAccording to simulated position, award simulated vote\t\n",
    "\t\t\tAdd simulated vote to array ONE_SIMULATION\n",
    "\t\t}\n",
    "\t\tDetermine average simulated vote as average of array ONE_SIMULATION\n",
    "\t\tAdd simulated vote to array AVERAGE_SIMULATION\n",
    "\t}\n",
    "\tSort AVERAGE_SIMULATION and determine the vote at the top 5th percentile\n",
    "\tIf actual average vote is greater than the 5th percentile of AVERAGE_SIMULATION\n",
    "\t\tThen DONOR votes significantly for RECIPIENT at the 5% level\n",
    "}\n",
    "\n",
    "If the same is true for RECIPIENT to DONOR, then there is collusive voting at the 5% significance level.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxillary function to simulate jury and public votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vote simulation\n",
    "\n",
    "def simulate_jury_votes(countries_each_year, num_simulations:int = 10):\n",
    "    \"\"\"\n",
    "    Note that with numpy we can create the simulation without running ANY for loops.\n",
    "    To do this, randomize the ranks that country X gives to country Y.\n",
    "    Each row is a simulation over the TIMESPAN. \n",
    "        - In other words, one simulation of country X randomly giving its points to Y over the course of chosen years.\n",
    "    Each column is the ranking awarded to country Y that year.\n",
    "    \"\"\"\n",
    "    ranks = pd.DataFrame(\n",
    "        data = rng.integers(low=1, high=countries_each_year, size=(num_simulations,len(countries_each_year))),\n",
    "        columns = countries_each_year.index\n",
    "    )\n",
    "\n",
    "    # to verify if the randomized ranks are correct: \n",
    "    #   set run ranks.max() many times and make sure it does not exceed PARTICIPANTS_BY_YEAR\n",
    "    assert (countries_each_year - ranks.max()).sum() >= 0\n",
    "\n",
    "    # convert ranks to points (the np.where with np.searchsorted thing), then convert to %\n",
    "    points = np.where(ranks > 10, 0, \n",
    "        12 - np.searchsorted([1,1.5,2,2.5,3,4,5,6,7,8,9,10], ranks)\n",
    "    )\n",
    "    return points\n",
    "\n",
    "def simulate_televotes(countries_each_year, no_televote, num_simulations : int = 10):\n",
    "    \"\"\"\n",
    "    this more or less the same as the jury voting, except years with no televotes are set to 0.\n",
    "    \"\"\"\n",
    "    ranks = pd.DataFrame(\n",
    "        data = rng.integers(low=1, high=countries_each_year, size=(num_simulations,len(countries_each_year))),\n",
    "        columns = countries_each_year.index\n",
    "    )\n",
    "    assert (countries_each_year - ranks.max()).sum() >= 0\n",
    "\n",
    "    ranks[no_televote.index] = 256 # arbitrary, this is just some value that is more that 10, so it will be set to 0 later\n",
    "    # convert ranks to points (the np.where with np.searchsorted thing), then convert to %\n",
    "    points = np.where(ranks > 10, 0, \n",
    "        12 - np.searchsorted([1,1.5,2,2.5,3,4,5,6,7,8,9,10], ranks)\n",
    "    )\n",
    "    return points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxillary function to graph simulated voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def graph_distribution(simluated_distribution, actual_mean, **plot_data):\n",
    "    S = pd.Series(simluated_distribution)\n",
    "\n",
    "    # plot density graph\n",
    "    plt.hist(S, color = 'blue', edgecolor = 'black', bins = 12)\n",
    "    # draw actual mean\n",
    "    plt.axvline(x=actual_mean, label=f'actual mean ({\"{0:.2f}\".format(actual_mean)})', c='r')\n",
    "    # ax = S.plot.kde()\n",
    "\n",
    "    # other information used for plotting graph\n",
    "    from_country, to_country = plot_data.get(\"From\", \"\"), plot_data.get(\"To\", \"\")\n",
    "    from_year, to_year = plot_data.get(\"start\", \"\"), plot_data.get(\"end\", \"\")\n",
    "    num_simulations = plot_data.get(\"n_sim\", \"\")\n",
    "    has_favouritism = plot_data.get(\"has_favouritism\", False)\n",
    "\n",
    "\n",
    "    title = f\"\"\"\n",
    "    Voting simulation\n",
    "    { '{} to {}'.format(from_country, to_country) if (from_country and to_country) else '' } {'(favouritism detected)' if has_favouritism else ''}\n",
    "    {'({} to {})'.format(from_year, to_year) if (from_year and to_year) else '' }\n",
    "    {'(n = {} rounds)'.format(num_simulations) if num_simulations else ''}\n",
    "    \"\"\"\n",
    "\n",
    "    # setting up title\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"frequency\")\n",
    "    plt.xlabel(\"average % points given (out of max. possible points given)\")\n",
    "\n",
    "    # show legend (for actual_mean) and plot\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define favouritism function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def favouritism(\n",
    "    csv, \n",
    "    country_x: str, country_y: str,\n",
    "    start_year: int, end_year: int,\n",
    "    num_simulations:int=100000,\n",
    "    confidence_threshold=95,\n",
    "    plot_data=False,\n",
    "    return_detailed_data=False,\n",
    "):\n",
    "\n",
    "    # countries cannot vote for themselves\n",
    "    if country_x == country_y: return False\n",
    "\n",
    "    # get relevant years and columns\n",
    "    by_year = csv[\n",
    "        (start_year <= csv.Year) & (csv.Year <= end_year) \n",
    "        & (csv.From_country == country_x) & (csv.To_country == country_y) \n",
    "    ]\n",
    "\n",
    "    if len(by_year) == 0: \n",
    "        # print(f\"could not find records for {country_x} -> {country_y} (make sure the spelling is correct)\")\n",
    "        return None\n",
    "\n",
    "    # Determine which years that X actually voted for Y (since it is possible that X could not vote for Y in some years)\n",
    "    timespan = by_year.Year\n",
    "\n",
    "    # determine number of countries each year\n",
    "    countries_each_year = PARTICIPANTS_BY_YEAR[ timespan ]\n",
    "\n",
    "    # determine $\\bar{x}$, the average amount of points (as a %) that X gave to Y over the course of the timespan.\n",
    "    actual_average = by_year.Points_total.mean()\n",
    "\n",
    "    # determine which years did not have any televotes\n",
    "    has_televote = HAS_TELEVOTE_BY_YEAR[ timespan ]\n",
    "    no_televote = has_televote[has_televote == False]\n",
    "\n",
    "    # simulate jury and public votes. for televotes, years that had no televotes just return 0.\n",
    "    jury_votes, televotes = simulate_jury_votes(countries_each_year, num_simulations), simulate_televotes(countries_each_year, no_televote, num_simulations)\n",
    "    simulated_points = jury_votes + televotes\n",
    "    points_percentage = simulated_points / MAX_POSSIBLE_POINTS_RECEIVED[timespan].values # normalisation\n",
    "\n",
    "    # generate S from simulated points\n",
    "    simulation_avgs = points_percentage.mean(axis=1)\n",
    "    # sort S to obtain a simulation of a normal distribution\n",
    "    simluated_distribution = np.sort(simulation_avgs, axis=None)\n",
    "    # sanity check\n",
    "    assert simluated_distribution.min() >= 0\n",
    "\n",
    "    # determine if favouritism occurred\n",
    "    simulated_95th_percentile = np.percentile(simluated_distribution, confidence_threshold)\n",
    "    has_favouritism = actual_average > simulated_95th_percentile\n",
    "    # if has_favouritism: print(f\"Favouritism from {country_x} to {country_y}\")\n",
    "\n",
    "    # plot data\n",
    "    if plot_data:\n",
    "        graph_distribution(\n",
    "            simluated_distribution, actual_average, \n",
    "            n_sim=num_simulations,\n",
    "            From=country_x, To=country_y,\n",
    "            start=start_year, end=end_year,\n",
    "            has_favouritism=has_favouritism\n",
    "        )\n",
    "\n",
    "    if return_detailed_data:\n",
    "        if has_favouritism:\n",
    "            return {\n",
    "                \"actual_avg\": actual_average,\n",
    "                \"sim_avg\": simulated_95th_percentile,\n",
    "            }\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return has_favouritism\n",
    "\n",
    "\n",
    "\n",
    "# verify searchsorted is working as intended (not required)\n",
    "# assert (\n",
    "#     ( 12 - np.searchsorted([1,1.5,2,2.5,3,4,5,6,7,8,9,10], [1,2,3,4,5,6,7,8,9,10]) ) \n",
    "#     ==\n",
    "#     np.array([12,10,8,7,6,5,4,3,2,1])\n",
    "# ).all() == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define collusion function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collusion(\n",
    "    csv,\n",
    "    country_x: str, country_y: str,\n",
    "    start_year: int, end_year: int,\n",
    "    **kwargs\n",
    "):\n",
    "    return favouritism(csv, country_x, country_y, start_year, end_year, **kwargs) and \\\n",
    "           favouritism(csv, country_y, country_x, start_year, end_year, **kwargs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxillary function to collect detection results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## matrix to store favouritism/collusion\n",
    "def get_favouritism_matrix(points, start_year: int = 1999, end_year: int = 2019):\n",
    "    filtered_by_year = points[(start_year <= points.Year) & (points.Year <= end_year)]\n",
    "    all_participants = sorted(set(filtered_by_year[\"From_country\"].unique()) | set(filtered_by_year[\"To_country\"].unique()))\n",
    "    favouritism_matrix = pd.DataFrame(\n",
    "        index=all_participants,\n",
    "        columns=all_participants,\n",
    "        data=False\n",
    "    )\n",
    "    for donor in favouritism_matrix.index:\n",
    "        for recipient in favouritism_matrix.columns:\n",
    "            result = favouritism(points, donor, recipient, start_year, end_year)\n",
    "            if result == None:\n",
    "                pass\n",
    "                # print(f\"no points were given from {donor} to {recipient} ({start_year}-{end_year})\")\n",
    "            if result == True:\n",
    "                favouritism_matrix.at[donor, recipient] = True\n",
    "    return favouritism_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run detection algorithm and collect results\n",
    "\n",
    "To this end, we can use several of the functions defined above to determine the favouritism under various circumstances. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine favouritism from country A to country B individually\n",
    "\n",
    "To determine whether country A voted for country B an exceptional amount of times (indicating favouritism) over a span of several years, simply run the `favouritism` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check favouritism individually\n",
    "\n",
    "# determine whether Norway showed favouritism to Sweden from 2000 to 2018\n",
    "print(favouritism(points, \"Norway\", \"Sweden\", 2000, 2018))\n",
    "# determine whether Sweden showed favouritism to Norway from 2000 to 2018\n",
    "print(favouritism(points, \"Sweden\", \"Norway\", 2000, 2018))\n",
    "# determine whether Norway and Sweden voted collusively (showed favourtism towards each other) from 2000 to 2018\n",
    "print(collusion(points, \"Sweden\", \"Norway\", 2000, 2018))\n",
    "\n",
    "# determine whether Croatia showed favouritism to Germany from 2014 to 2019\n",
    "print(favouritism(points, \"Croatia\", \"Germany\", 2014, 2019))\n",
    "\n",
    "# determine whether Malta and Cyprus voted collusively (showed favourtism towards each other) from 2000 to 2018\n",
    "print(collusion(points, \"Malta\", \"Cyprus\", 2000, 2018))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine favouritism between all countries\n",
    "\n",
    "For this, run `get_favouritism_matrix` and select a specific timeframe of years to determine favouritism on, e.g. from 2015 to 2019.\n",
    "\n",
    "Note that this function will take some time to finish.\n",
    "\n",
    "The output of this function is a 2D matrix, where the position (A, B) is the favouritism from A to B. \n",
    "\n",
    "For example, if `favouritism_matrix[\"Belgium\", \"Bulgaria\"]` is `True`, then Belgium showed favouritism to Bulgaria within the specified timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "favouritism_matrix = get_favouritism_matrix(points, 2015, 2019)\n",
    "\n",
    "favouritism_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `get_favouritism_matrix`, we can quickly determine which countries a certain country shows favouritism to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(favouritism_matrix.loc[\"Cyprus\"][favouritism_matrix.loc[\"Cyprus\"] == True].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualise results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the results of favouritism from `get_favouritism_matrix`.\n",
    "\n",
    "Note that for large amounts of countries, this map becomes very hard to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_favouritism_graph_from_adjacency_matrix(matrix):\n",
    "    rows, cols = np.where(matrix)\n",
    "    edges = list(zip(matrix.index[rows], matrix.columns[cols]))\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "    positions = nx.circular_layout(G, scale=0.9, center=(0,0))\n",
    "\n",
    "    def label_pos(x, y, move):\n",
    "        return (x*move, y*move)\n",
    "\n",
    "    label_positions = {n: label_pos(x, y, 1.15)\n",
    "                 for n, (x, y) in positions.items()}\n",
    "    nx.draw_networkx(G, pos=positions, with_labels=False, node_size=40)\n",
    "    nx.draw_networkx_labels(G, pos=label_positions, font_size=10, font_color=\"green\")\n",
    "\n",
    "draw_favouritism_graph_from_adjacency_matrix(favouritism_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise results of countries that collude with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_collusion_graph_from_adjacency_matrix(matrix):\n",
    "    collusion_matrix = matrix & matrix.transpose()\n",
    "    draw_favouritism_graph_from_adjacency_matrix(collusion_matrix)\n",
    "\n",
    "draw_collusion_graph_from_adjacency_matrix(favouritism_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save favouritism results into a dataframe.\n",
    "\n",
    "This is an alternative to producing an entire favouritism matrix, which is usually very sparse.\n",
    "\n",
    "Instead, we can save just the instances of favouritism into a dataframe further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_one_result(start_year, end_year, num_simulations=100000, confidence_threshold=95):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    filtered_by_year = points[(start_year <= points.Year) & (points.Year <= end_year)]\n",
    "    all_participants = sorted(set(filtered_by_year[\"From_country\"].unique()) | set(filtered_by_year[\"To_country\"].unique()))\n",
    "    for donor in all_participants:\n",
    "        for recipient in all_participants:\n",
    "            result = favouritism(points, donor, recipient, start_year, end_year,\n",
    "                num_simulations=num_simulations,\n",
    "                confidence_threshold=confidence_threshold,\n",
    "                return_detailed_data=True\n",
    "            )\n",
    "            if result:\n",
    "                results += [(start_year, end_year, donor, recipient, result[\"actual_avg\"], result[\"sim_avg\"])]\n",
    "    return results\n",
    "\n",
    "def compile_favouritism_results(years_list, num_simulations=100000, confidence_threshold=95):\n",
    "    columns = (\"start_year\", \"end_year\", \"from_country\", \"to_country\", \"real_avg\", \"sim_avg\")\n",
    "    results = []\n",
    "    for years in years_list:\n",
    "        result = compile_one_result(\n",
    "            years[0], years[1],\n",
    "            num_simulations, confidence_threshold\n",
    "        )\n",
    "        if result: results += result\n",
    "    \n",
    "    result_dataframe = pd.DataFrame(results, columns=columns)\n",
    "    params = {\n",
    "        \"num_simulations\": [num_simulations],\n",
    "        \"confidence_threshold\": [confidence_threshold],\n",
    "    }\n",
    "    parameters = pd.DataFrame(data=params)\n",
    "    return result_dataframe, parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `compile_results`, supply it with a list of time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [\n",
    "    (1975, 1980),\n",
    "    (1981, 1985),\n",
    "    # (1986, 1990),\n",
    "    # (1991, 1995),\n",
    "    # (1996, 2000),\n",
    "    # (2001, 2005),\n",
    "    # (2006, 2010),\n",
    "    # (2011, 2015),\n",
    "    # (2016, 2019),\n",
    "]\n",
    "\n",
    "result_dataframe, parameters = compile_favouritism_results(years, 100000)\n",
    "result_dataframe\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
